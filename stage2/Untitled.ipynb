{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Start Training\n",
      "========== Epoch 1/1 ==========\n",
      "..\\data\\I\\001628.jpg does not exist!\n",
      "..\\data\\I\\003401.jpg does not exist!\n",
      "..\\data\\I\\000214.jpg does not exist!\n",
      "..\\data\\II\\006911.jpg does not exist!\n",
      "..\\data\\I\\004123.jpg does not exist!\n",
      "..\\data\\I\\000912.jpg does not exist!\n",
      "..\\data\\II\\009161.jpg does not exist!\n",
      "..\\data\\II\\008459.jpg does not exist!\n",
      "..\\data\\II\\008701.jpg does not exist!\n",
      "..\\data\\I\\002042.jpg does not exist!\n",
      "..\\data\\I\\004587.jpg does not exist!\n",
      "..\\data\\I\\003031.jpg does not exist!\n",
      "..\\data\\II\\008474.jpg does not exist!\n",
      "..\\data\\II\\008308.jpg does not exist!\n",
      "..\\data\\I\\005326.jpg does not exist!\n",
      "..\\data\\II\\008993.jpg does not exist!\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-98cbc262a8b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-98cbc262a8b7>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Train'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'===> Start Training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mlest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lest_loss_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlest_loss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a+'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/private/project3/stage1/Actions.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, data_loaders, model, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# set model to evaluate mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                 \u001b[0;31m# get data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "# from stage1.Network import Net\n",
    "# from stage1.Dataset import FaceLandmarksDataset\n",
    "# from stage1.Actions import *\n",
    "from Network import Net\n",
    "from Dataset import FaceLandmarksDataset\n",
    "from Actions import *\n",
    "\n",
    "\n",
    "DATAPATH = './'\n",
    "LABLE_FILE_NAME = {'train': 'train.txt', 'test': 'test.txt'}\n",
    "\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "\n",
    "\n",
    "def main():\n",
    "    # set arguments\n",
    "    parser = argparse.ArgumentParser(description='Detector')\n",
    "    parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                        help='disables CUDA training')\n",
    "    parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                        help='random seed (default: 1)')\n",
    "\n",
    "    parser.add_argument('--train-batch-size', type=int, default=16, metavar='N',\n",
    "                       help='input batch size for training (default: 128)')\n",
    "    parser.add_argument('--test-batch-size', type=int, default=16, metavar='N',\n",
    "                       help='input batch size for testing (default: 128)')\n",
    "    parser.add_argument('--epochs', type=int, default=1, metavar='N',\n",
    "                        help='input the number of epochs to train (default: 1000)')\n",
    "    parser.add_argument('--learning-rate', type=float, default=0.0001, metavar='LR',\n",
    "                        help='input the learning rate of optimizer (default: 0.00008)')\n",
    "    parser.add_argument('--momentum', type=float, default=0.3, metavar='M',\n",
    "                        help='input the momentum of optimizer (default: 0.25)')\n",
    "    parser.add_argument('--log-interval', type=int, default=20, metavar='N',\n",
    "                        help='how many batches to wait before logging training status')\n",
    "    parser.add_argument('--save-model', action='store_true', default=True,\n",
    "                        help='save the current model')\n",
    "    parser.add_argument('--save-directory', type=str, default='trained_models',\n",
    "                        help='the directory to save learnt models')\n",
    "\n",
    "    parser.add_argument('--phase', type=str, default='train',\n",
    "                        help='choose from Train/train, Test/test, Predict/predict, Finetune/finetune')\n",
    "\n",
    "#     args = parser.parse_args()\n",
    "    args = parser.parse_args(args=[])\n",
    "\n",
    "    # process control\n",
    "    torch.manual_seed(args.seed)\n",
    "    is_use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if is_use_cuda else \"cpu\")\n",
    "    datasets = {x: FaceLandmarksDataset(DATAPATH, LABLE_FILE_NAME[x], data_transforms[x])\n",
    "                for x in ['train', 'test']}\n",
    "    train_loader = DataLoader(datasets['train'], batch_size=args.train_batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(datasets['test'], batch_size=args.test_batch_size)\n",
    "    data_loaders = {'train': train_loader, 'val': test_loader}\n",
    "    model = Net().to(device)\n",
    "\n",
    "    # training control\n",
    "    criterion = nn.MSELoss(reduction='mean')\n",
    "    optimizer = optim.SGD(model.parameters(), lr=args.learning_rate, momentum=args.momentum)\n",
    "\n",
    "    # phase control\n",
    "    if args.phase == 'Train' or args.phase == 'train':\n",
    "        print('===> Start Training')\n",
    "        lest_loss = train(args, data_loaders, model, criterion, optimizer, device)\n",
    "        f = open('lest_loss_' + str(lest_loss) + '.txt', 'a+')\n",
    "        [print(k, file=f) for k in args.__dict__.items()]\n",
    "        [print(optimizer, file=f)]\n",
    "        f.close()\n",
    "\n",
    "    elif args.phase == 'Test' or args.phase == 'test':\n",
    "        print('===> Start Testing')\n",
    "        test_model = model\n",
    "        test_model.load_state_dict(torch.load('./trained_models/best_model.pt'))\n",
    "        avg_loss = test(test_loader, device, criterion, test_model)\n",
    "        print('Average loss for test set is {:.2f}. '.format(avg_loss))\n",
    "\n",
    "    elif args.phase == 'Finetune' or args.phase == 'finetune':\n",
    "        print('===> Start Finetuning')\n",
    "        pretrained_model = model\n",
    "        pretrained_model.load_state_dict(torch.load('./trained_models/best_model.pt'))\n",
    "        trainable_vars = [pretrained_model.ip3.bias, pretrained_model.ip3.weight]\n",
    "        optimizer = optim.SGD(trainable_vars, lr=args.learning_rate, momentum=args.momentum)\n",
    "        train(args, data_loaders, pretrained_model, criterion, optimizer, device)\n",
    "\n",
    "    elif args.phase == 'Predict' or args.phase == 'predict':\n",
    "        print('===> Predict')\n",
    "        img_dir_name = './data/I/001063.jpg'\n",
    "        test_model = model\n",
    "        test_model.load_state_dict(torch.load('./trained_models/best_model.pt'))\n",
    "        predict(img_dir_name, test_model, device)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files train.txt and test.txt saved! \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "DATAPATH = '../data'\n",
    "FOLDER_LIST = ['I', 'II']\n",
    "LABLE_FILE_NAME = ['label.txt', 'label.txt']\n",
    "valset_ratio = 0.3\n",
    "\n",
    "\n",
    "def expand_roi(x1, y1, x2, y2, img_width, img_height, ratio):   # usually ratio = 0.25\n",
    "    width = x2 - x1 + 1\n",
    "    height = y2 - y1 + 1\n",
    "    padding_width = int(width * ratio)\n",
    "    padding_height = int(height * ratio)\n",
    "    roi_x1 = x1 - padding_width\n",
    "    roi_y1 = y1 - padding_height\n",
    "    roi_x2 = x2 + padding_width\n",
    "    roi_y2 = y2 + padding_height\n",
    "    roi_x1 = 0 if roi_x1 < 0 else roi_x1\n",
    "    roi_y1 = 0 if roi_y1 < 0 else roi_y1\n",
    "    roi_x2 = img_width - 1 if roi_x2 >= img_width else roi_x2\n",
    "    roi_y2 = img_height - 1 if roi_y2 >= img_height else roi_y2\n",
    "    return roi_x1, roi_y1, roi_x2, roi_y2, \\\n",
    "           roi_x2 - roi_x1 + 1, roi_y2 - roi_y1 + 1\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_set_file = open('train.txt', 'w')\n",
    "    test_set_file = open('test.txt', 'w')\n",
    "    for folder in range(len(FOLDER_LIST)):\n",
    "        num = 1\n",
    "        path = DATAPATH + '/' + FOLDER_LIST[folder]\n",
    "        data_set_size = len(open(path + '/' + LABLE_FILE_NAME[folder]).readlines())\n",
    "        labels = open(path + '/' + LABLE_FILE_NAME[folder])\n",
    "        for line in labels:\n",
    "            label = line.split()\n",
    "            file_name = label[0]\n",
    "            file_path = path + '/' + file_name\n",
    "            x1, y1, x2, y2 = [float(i) for i in label[1:5]]\n",
    "            key_points = np.array([float(i) for i in label[5:]]).reshape(-1, 2)\n",
    "            try:\n",
    "                img = cv2.imread(file_path)\n",
    "            except Exception:\n",
    "                print('Not a valid image.')\n",
    "            else:\n",
    "                h, w, _ = img.shape\n",
    "                roi_x1, roi_y1, roi_x2, roi_y2, _, _ = expand_roi(x1, y1, x2, y2, w, h, 0.25)\n",
    "                landmarks = key_points - np.array([roi_x1, roi_y1])\n",
    "\n",
    "                #show image to check labels\n",
    "                # img = img[int(roi_y1):int(roi_y2), int(roi_x1):int(roi_x2)]\n",
    "                # img = cv2.rectangle(img, (int(roi_x1), int(roi_y1)), (int(roi_x2), int(roi_y2)), (0, 255, 0), 1)\n",
    "                # for point in landmarks:\n",
    "                #     x, y = point\n",
    "                #     cv2.circle(img, (int(x), int(y)), 1, (0, 0, 255), 0)\n",
    "                # cv2.imshow('img', img)\n",
    "                # key = cv2.waitKey(1000)\n",
    "                # if key == 27:\n",
    "                #     exit(0)\n",
    "                # cv2.destroyAllWindows()\n",
    "\n",
    "                list = [str(i) for i in [roi_x1, roi_y1, roi_x2, roi_y2] + landmarks.reshape(1, -1).squeeze(0).tolist()]\n",
    "                line = file_path + ' ' + ' '.join(list) + '\\n'\n",
    "                if num <= valset_ratio * data_set_size:\n",
    "                    test_set_file.write(line)\n",
    "                else:\n",
    "                    train_set_file.write(line)\n",
    "                num += 1\n",
    "    train_set_file.close()\n",
    "    test_set_file.close()\n",
    "    print('Files train.txt and test.txt saved! ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
